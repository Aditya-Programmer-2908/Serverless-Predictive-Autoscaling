{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T03:27:39.097586Z",
     "iopub.status.busy": "2025-09-22T03:27:39.097265Z",
     "iopub.status.idle": "2025-09-22T04:52:52.584317Z",
     "shell.execute_reply": "2025-09-22T04:52:52.583223Z",
     "shell.execute_reply.started": "2025-09-22T03:27:39.097562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ----------------------------\n",
    "# Load Dataset\n",
    "# ----------------------------\n",
    "file_path = '/kaggle/input/azure-functions-2021-dataset/AzureFunctionsInvocationTraceForTwoWeeksJan2021.txt'\n",
    "df = pd.read_csv(file_path, sep=',', header=None, names=['app','func','end_timestamp','duration'])\n",
    "\n",
    "# ----------------------------\n",
    "# Clean and convert columns\n",
    "# ----------------------------\n",
    "df['end_timestamp'] = pd.to_datetime(pd.to_numeric(df['end_timestamp'], errors='coerce'), unit='s')\n",
    "df['duration'] = pd.to_numeric(df['duration'], errors='coerce')\n",
    "df = df.dropna(subset=['app','func','end_timestamp','duration'])\n",
    "df = df.sort_values(['app','func','end_timestamp']).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Cold start flag\n",
    "# ----------------------------\n",
    "df['prev_timestamp'] = df.groupby(['app','func'])['end_timestamp'].shift(1)\n",
    "df['time_diff'] = (df['end_timestamp'] - df['prev_timestamp']).dt.total_seconds()\n",
    "df['cold_start_flag'] = df['time_diff'].apply(lambda x: 1 if pd.isnull(x) or x > 1800 else 0)\n",
    "df = df.drop(columns=['prev_timestamp','time_diff'])\n",
    "\n",
    "# ----------------------------\n",
    "# Feature engineering\n",
    "# ----------------------------\n",
    "df['hour'] = df['end_timestamp'].dt.hour\n",
    "df['dayofweek'] = df['end_timestamp'].dt.dayofweek\n",
    "\n",
    "# Encode categorical variables\n",
    "app_enc = LabelEncoder()\n",
    "func_enc = LabelEncoder()\n",
    "df['app_enc'] = app_enc.fit_transform(df['app'])\n",
    "df['func_enc'] = func_enc.fit_transform(df['func'])\n",
    "\n",
    "# ----------------------------\n",
    "# Log-transform duration to reduce skew\n",
    "# ----------------------------\n",
    "df['duration_log'] = np.log1p(df['duration'])\n",
    "\n",
    "# ----------------------------\n",
    "# Sliding window creation\n",
    "# ----------------------------\n",
    "WINDOW_SIZE = 5\n",
    "feature_cols = ['duration_log', 'app_enc', 'func_enc', 'hour', 'dayofweek']\n",
    "X_windows, y_dur, y_cold = [], [], []\n",
    "\n",
    "for func_id, func_df in df.groupby('func_enc'):\n",
    "    func_df = func_df.reset_index(drop=True)\n",
    "    for i in range(WINDOW_SIZE, len(func_df)):\n",
    "        window = func_df[feature_cols].iloc[i-WINDOW_SIZE:i].values\n",
    "        target_duration = func_df['duration_log'].iloc[i]\n",
    "        target_cold = func_df['cold_start_flag'].iloc[i]\n",
    "\n",
    "        X_windows.append(window)\n",
    "        y_dur.append(target_duration)\n",
    "        y_cold.append(target_cold)\n",
    "\n",
    "X_windows = np.array(X_windows)\n",
    "y_dur = np.array(y_dur).reshape(-1,1)\n",
    "y_cold = np.array(y_cold).reshape(-1,1)\n",
    "\n",
    "# ----------------------------\n",
    "# Scale features and target\n",
    "# ----------------------------\n",
    "scaler_X = MinMaxScaler()\n",
    "X_windows[:,:,0] = scaler_X.fit_transform(X_windows[:,:,0])  # only scale duration_log\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_dur_scaled = scaler_y.fit_transform(y_dur)\n",
    "\n",
    "# ----------------------------\n",
    "# Train/test split\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train_dur, y_test_dur, y_train_cold, y_test_cold = train_test_split(\n",
    "    X_windows, y_dur_scaled, y_cold, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# LSTM Model (Multi-output)\n",
    "# ----------------------------\n",
    "input_layer = Input(shape=(WINDOW_SIZE, len(feature_cols)))\n",
    "x = LSTM(64, activation='tanh')(input_layer)\n",
    "dur_output = Dense(1, name='duration_output')(x)\n",
    "cold_output = Dense(1, activation='sigmoid', name='cold_output')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[dur_output, cold_output])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'duration_output':'mse', 'cold_output':'binary_crossentropy'},\n",
    "    metrics={'duration_output':'mae', 'cold_output':'accuracy'}\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Training with early stopping\n",
    "# ----------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'duration_output': y_train_dur, 'cold_output': y_train_cold},\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Prediction and inverse transform\n",
    "# ----------------------------\n",
    "y_pred_dur_scaled, y_pred_cold = model.predict(X_test, batch_size=256)\n",
    "y_pred_dur = scaler_y.inverse_transform(y_pred_dur_scaled)\n",
    "y_pred_dur = np.expm1(y_pred_dur)  # inverse log1p\n",
    "y_test_dur_exp = np.expm1(scaler_y.inverse_transform(y_test_dur))\n",
    "\n",
    "# ----------------------------\n",
    "# Sample Output\n",
    "# ----------------------------\n",
    "for i in range(10):\n",
    "    print(f\"True Duration: {y_test_dur_exp[i][0]:.3f}, Predicted: {y_pred_dur[i][0]:.3f}, Predicted Cold Start: {int(round(y_pred_cold[i][0]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T05:10:16.366837Z",
     "iopub.status.busy": "2025-09-22T05:10:16.366424Z",
     "iopub.status.idle": "2025-09-22T05:10:16.892638Z",
     "shell.execute_reply": "2025-09-22T05:10:16.891611Z",
     "shell.execute_reply.started": "2025-09-22T05:10:16.366797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Inverse transform predictions & ground truth\n",
    "# -------------------------\n",
    "y_pred_dur_inv = scaler_y.inverse_transform(y_pred_dur)\n",
    "y_true_dur_inv = scaler_y.inverse_transform(y_test_dur)\n",
    "\n",
    "# Clip negatives (since durations can't be negative)\n",
    "y_pred_dur_inv = np.clip(y_pred_dur_inv, 0, None)\n",
    "\n",
    "# Select a sample for plotting (first 200 for clarity)\n",
    "sample_size = 200\n",
    "true_sample = y_true_dur_inv[:sample_size].flatten()\n",
    "pred_sample = y_pred_dur_inv[:sample_size].flatten()\n",
    "\n",
    "# -------------------------\n",
    "# Scatter plot: True vs Predicted durations\n",
    "# -------------------------\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(range(sample_size), true_sample, color='blue', label='True Duration', alpha=0.6)\n",
    "plt.scatter(range(sample_size), pred_sample, color='red', label='Predicted Duration', alpha=0.6)\n",
    "plt.title(\"True vs Predicted Durations (Sample of 200)\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Duration (seconds)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# Error distribution\n",
    "# -------------------------\n",
    "errors = pred_sample - true_sample\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(errors, bins=50, color='orange', alpha=0.7)\n",
    "plt.title(\"Prediction Errors Distribution\")\n",
    "plt.xlabel(\"Prediction Error (Predicted - True)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T05:11:00.127398Z",
     "iopub.status.busy": "2025-09-22T05:11:00.127044Z",
     "iopub.status.idle": "2025-09-22T05:11:00.570420Z",
     "shell.execute_reply": "2025-09-22T05:11:00.569504Z",
     "shell.execute_reply.started": "2025-09-22T05:11:00.127376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure y_pred_cold is integer (0/1) and aligned with true labels\n",
    "y_pred_cold = (y_pred_cold > 0.5).astype(int).flatten()\n",
    "y_true_cold = y_test_cold[:len(y_pred_cold)].flatten()\n",
    "\n",
    "# -------------------------\n",
    "# Confusion matrix\n",
    "# -------------------------\n",
    "cm = confusion_matrix(y_true_cold, y_pred_cold, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Cold Start', 'Cold Start'])\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Cold Start Prediction Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# True vs Predicted bar chart\n",
    "# -------------------------\n",
    "true_counts = np.bincount(y_true_cold, minlength=2)\n",
    "pred_counts = np.bincount(y_pred_cold, minlength=2)\n",
    "\n",
    "labels = ['No Cold Start', 'Cold Start']\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x-0.2, true_counts, width=0.4, label='True', color='blue')\n",
    "plt.bar(x+0.2, pred_counts, width=0.4, label='Predicted', color='red')\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Cold Start: True vs Predicted Counts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T05:11:08.343264Z",
     "iopub.status.busy": "2025-09-22T05:11:08.342322Z",
     "iopub.status.idle": "2025-09-22T05:11:08.718058Z",
     "shell.execute_reply": "2025-09-22T05:11:08.717083Z",
     "shell.execute_reply.started": "2025-09-22T05:11:08.343232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Cold start metrics\n",
    "# -------------------------\n",
    "y_true_cold = y_test_cold[:len(y_pred_cold)].flatten()\n",
    "y_pred_cold_flat = y_pred_cold.flatten()\n",
    "\n",
    "cold_accuracy = accuracy_score(y_true_cold, y_pred_cold_flat)\n",
    "cold_precision = precision_score(y_true_cold, y_pred_cold_flat)\n",
    "cold_recall = recall_score(y_true_cold, y_pred_cold_flat)\n",
    "cold_f1 = f1_score(y_true_cold, y_pred_cold_flat)\n",
    "\n",
    "print(\"Cold Start Metrics:\")\n",
    "print(f\"Accuracy : {cold_accuracy:.4f}\")\n",
    "print(f\"Precision: {cold_precision:.4f}\")\n",
    "print(f\"Recall   : {cold_recall:.4f}\")\n",
    "print(f\"F1-Score : {cold_f1:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Duration metrics\n",
    "# -------------------------\n",
    "y_true_dur = y_true_dur_inv.flatten()\n",
    "y_pred_dur_final = y_pred_dur_inv.flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_true_dur, y_pred_dur_final)\n",
    "mse = mean_squared_error(y_true_dur, y_pred_dur_final)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true_dur, y_pred_dur_final)\n",
    "\n",
    "print(\"\\nDuration Metrics:\")\n",
    "print(f\"MAE  : {mae:.4f}\")\n",
    "print(f\"MSE  : {mse:.4f}\")\n",
    "print(f\"RMSE : {rmse:.4f}\")\n",
    "print(f\"R2   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T05:11:15.057977Z",
     "iopub.status.busy": "2025-09-22T05:11:15.057663Z",
     "iopub.status.idle": "2025-09-22T05:11:15.063907Z",
     "shell.execute_reply": "2025-09-22T05:11:15.062616Z",
     "shell.execute_reply.started": "2025-09-22T05:11:15.057952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_rows = df.shape[0]\n",
    "print(f\"Number of rows in df: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T05:11:17.503406Z",
     "iopub.status.busy": "2025-09-22T05:11:17.502673Z",
     "iopub.status.idle": "2025-09-22T05:11:17.556212Z",
     "shell.execute_reply": "2025-09-22T05:11:17.555230Z",
     "shell.execute_reply.started": "2025-09-22T05:11:17.503368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Save model as H5\n",
    "model_path = \"lstm_model.h5\"\n",
    "model.save(model_path)\n",
    "\n",
    "# Create a ZIP file\n",
    "zip_path = \"lstm_model.zip\"\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    zipf.write(model_path)\n",
    "\n",
    "print(f\"Model saved and zipped at: {os.path.abspath(zip_path)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8314191,
     "sourceId": 13124763,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
